The configuration settings in the file kiarash_sandbox/confs/conf_train_cpc_model.py:

max_epochs = 1000
patience = 100
dropout = 0.1
batch_size = 32
learning_rate = 2e-4
num_frames_encoding = 100
future_predicted_timesteps = [1, 2, 3, 4]
train_model = 0
test_model = 1
rand_init = 0
load_model = 0
save_best_model = 1
print_conf_contents = 1
encoder_name = 'CPC_encoder'
autoregressive_model_name = 'CPC_autoregressive_model'
postnet_name = 'CPC_postnet'
rnn_models_used_in_ar_model = 0
dataset_name = 'CPCDataset'
loss_name = 'CPC_loss_no_classes' # 'CPC_loss_no_classes' | 'CPC_mse_loss'
loss_flag = 'nce' if loss_name == 'CPC_loss_no_classes' else 'mse'
loss_params = {'future_predicted_timesteps': future_predicted_timesteps}
optimization_algorithm = 'Adam'
optimization_algorithm_params = {'lr': learning_rate}
use_lr_scheduler = 0
lr_scheduler = 'ReduceLROnPlateau'
lr_scheduler_params = {'mode': 'min',
                       'factor': 0.5,
                       'patience': 30}
encoder_params = {'linear_1_input_dim': 128,
                  'linear_1_output_dim': 128,
                  'linear_2_input_dim': 128,
                  'linear_2_output_dim': 128,
                  'linear_3_input_dim': 128,
                  'linear_3_output_dim': 256,
                  'normalization_type': None,
                  'dropout': dropout}
ar_model_params = {'type': 'gru',
                   'encoding_dim': 256,
                   'output_dim': 256}
w_params = {'encoding_dim': 256,
            'ar_model_output_dim': 256,
            'future_predicted_timesteps': future_predicted_timesteps,
            'detach': False}
w_use_ldm_params = 0
encoder_best_model_name = f"kiarash_sandbox/models/CPC_Encoder_best_model_{ar_model_params['type']}_ldmfcst{w_use_ldm_params}.pt"
ar_best_model_name = f"kiarash_sandbox/models/CPC_AR_best_model_{ar_model_params['type']}_ldmfcst{w_use_ldm_params}.pt"
w_best_model_name = f"kiarash_sandbox/models/W_best_model_{ar_model_params['type']}_ldmfcst{w_use_ldm_params}.pt"
params_train = {'batch_size': batch_size,
                'shuffle': True,
                'drop_last': True,
                'num_workers': 0,
                'pin_memory': False}
params_test = {'batch_size': batch_size,
               'shuffle': False,
               'drop_last': True}
name_of_log_textfile = f"kiarash_sandbox/logs/trainlog_{ar_model_params['type']}_ldmfcst{w_use_ldm_params}_h{w_params['encoding_dim']}.txt"

########################################################################################



Process on cuda

Number of parameters:
Encoder #params:    66048 (%9.1)
AR #params:        394752 (%54.6)
W #params:         262144 (%36.3)
Total #params:  722944



Starting testing... => Testing loss:  1.2122

Word classification
train acc: 100.0000% 
testing acc : 54.6875%
